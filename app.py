import streamlit as st
import requests
from bs4 import BeautifulSoup
import jieba
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from pyecharts.charts import WordCloud, Bar, Line, Pie, Scatter, Radar, HeatMap
from pyecharts import options as opts
import string
import re
import pandas as pd
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨é»‘ä½“æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False    # æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


# å¯¹æ–‡æœ¬åˆ†è¯
def word_segmentation(text):
    words = jieba.lcut(text)
    words = [word for word in words if len(word) > 1 and not word.isspace()]
    return words


# è¯·æ±‚URLæŠ“å–æ–‡æœ¬å†…å®¹
def fetch_text_from_url(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # ç§»é™¤è„šæœ¬å’Œæ ·å¼å…ƒç´ 
    for script_or_style in soup(['script', 'style']):
        script_or_style.decompose()

    # è·å–çº¯æ–‡æœ¬
    text = soup.get_text()
    return text


# æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤æ ‡ç‚¹ç¬¦å·å’Œå…¶ä»–ä¸éœ€è¦çš„å­—ç¬¦
def clean_text(text):
    punctuation_to_remove = string.punctuation + "ï¼ï¼Ÿï½¡ï¼‚ï¼ƒï¼„ï¼…ï¼†ï¼‡ï¼ˆï¼‰ï¼Šï¼‹ï¼Œï¼ï¼ï¼šï¼›ï¼œï¼ï¼ï¼ ï¼»ï¼¼ï¼½ï¼¾ï¼¿ï½€ï½›ï½œï½ï½ï½ŸğŸ“ï½¢ï½£ã€ã€ƒã€ˆã€‰ã€Šã€‹ã€Œã€ã€ã€ã€ã€‘ã€”ã€•ã€–ã€—ã€˜ã€™ã€šã€›ã€œã€ã€ã€Ÿâš—ï¸ã€¾ã€¿â€“â€”â€˜â€™â€›â€œâ€â€â€Ÿâ€¦â€§ï¹."
    cleaned_text = re.sub(r'[{}]+'.format(re.escape(punctuation_to_remove)), '', text)
    cleaned_text = ' '.join(cleaned_text.split())
    return cleaned_text


# å¯¹æ–‡æœ¬åˆ†è¯, ç»Ÿè®¡è¯é¢‘
def count_word_frequency(words):
    counter = Counter(words)
    return counter

def plot_line(word_freq):
    line = (
        Line()
        .add_xaxis(list(word_freq.keys()))
        .add_yaxis("é¢‘ç‡", list(word_freq.values()))
        .set_global_opts(
            title_opts=opts.TitleOpts(title="è¯é¢‘å˜åŒ–è¶‹åŠ¿"),
            yaxis_opts=opts.AxisOpts(name="é¢‘ç‡"),
            xaxis_opts=opts.AxisOpts(name="è¯æ±‡"),
            toolbox_opts=opts.ToolboxOpts(is_show=True),
            datazoom_opts=[opts.DataZoomOpts()],
        )
    )
    return line
# ä½¿ç”¨Matplotlibç»˜åˆ¶æŸ±çŠ¶å›¾
def plot_bar_with_matplotlib(word_freq):
    fig, ax = plt.subplots(figsize=(10, 7))

    # å¦‚æœword_freqæ˜¯å­—å…¸ï¼Œåˆ™å…ˆæ’åºå†å–å‰20é¡¹
    sorted_items = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)[:20]
    words, freqs = zip(*sorted_items) if sorted_items else ([], [])

    # åˆ›å»ºæ¡å½¢å›¾
    ax.barh(words, freqs, color='skyblue')
    ax.invert_yaxis()  # labels read top-to-bottom

    # æ˜ç¡®è®¾ç½®yè½´çš„æ ‡ç­¾
    ax.set_yticks(range(len(words)))
    ax.set_yticklabels(words)

    ax.set_xlabel('é¢‘ç‡')
    ax.set_title('è¯é¢‘æ’åå‰20')

    # è°ƒæ•´å¸ƒå±€ä»¥é˜²æ­¢æ ‡ç­¾è¢«è£å‰ª
    plt.tight_layout()

    # æ—‹è½¬æ ‡ç­¾ä»¥é€‚åº”ç©ºé—´
    plt.xticks(rotation=45)

    st.pyplot(fig)

# ä½¿ç”¨Seabornç»˜åˆ¶çƒ­åŠ›å›¾
def plot_heatmap_with_seaborn(word_freq):
    data = pd.DataFrame(list(word_freq.items()), columns=['è¯æ±‡', 'é¢‘ç‡'])
    data = data.pivot_table(index='è¯æ±‡', values='é¢‘ç‡', aggfunc='sum').fillna(0)
    fig, ax = plt.subplots(figsize=(10, 7))
    sns.heatmap(data, annot=True, fmt=".1f", cmap="YlGnBu")
    ax.set_title('è¯é¢‘çƒ­åŠ›å›¾')
    st.pyplot(fig)


# ä½¿ç”¨Pyechartsç»˜åˆ¶è¯äº‘
def plot_wordcloud_with_pyecharts(word_freq):
    word_cloud = (
        WordCloud()
        .add(series_name="è¯æ±‡é¢‘ç‡", data_pair=word_freq.items(), word_size_range=[20, 100])
        .set_global_opts(
            title_opts=opts.TitleOpts(title="è¯é¢‘åˆ†å¸ƒè¯äº‘"),
            tooltip_opts=opts.TooltipOpts(is_show=True),
        )
    )
    return word_cloud


# ä½¿ç”¨Pyechartsç»˜åˆ¶é¥¼å›¾
def plot_pie_with_pyecharts(word_freq):
    pie = (
        Pie()
        .add("", list(word_freq.items())[:20])
        .set_global_opts(
            title_opts=opts.TitleOpts(title="è¯é¢‘æ¯”ä¾‹"),
            legend_opts=opts.LegendOpts(orient="vertical", pos_top="15%", pos_left="2%"),
        )
        .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c} ({d}%)"))
    )
    return pie


# ä½¿ç”¨Pyechartsç»˜åˆ¶æ•£ç‚¹å›¾
def plot_scatter_with_pyecharts(word_freq):
    scatter = (
        Scatter()
        .add_xaxis(list(word_freq.keys()))
        .add_yaxis("é¢‘ç‡", list(word_freq.values()))
        .set_global_opts(
            title_opts=opts.TitleOpts(title="è¯é¢‘æ•£ç‚¹å›¾"),
            yaxis_opts=opts.AxisOpts(name="é¢‘ç‡"),
            xaxis_opts=opts.AxisOpts(name="è¯æ±‡"),
            toolbox_opts=opts.ToolboxOpts(is_show=True),
        )
    )
    return scatter


# ä½¿ç”¨Pyechartsç»˜åˆ¶é›·è¾¾å›¾
def plot_radar_with_pyecharts(word_freq):
    top_words = list(word_freq.items())[:6]
    if not top_words:
        return None

    schema = [{"name": word, "max": max(word_freq.values())} for word, _ in top_words]

    radar = (
        Radar()
        .add_schema(schema)
        .add("é¢‘ç‡", [[freq for _, freq in top_words]])
        .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘é›·è¾¾å›¾"))
    )
    return radar


# ä½¿ç”¨Pyechartsç»˜åˆ¶çƒ­åŠ›å›¾
def plot_heatmap_with_pyecharts(word_freq):
    heatmap_data = [(i, 0, freq) for i, (word, freq) in enumerate(word_freq.items())]
    heatmap = (
        HeatMap()
        .add_xaxis(list(word_freq.keys()))
        .add_yaxis("é¢‘ç‡", ["é¢‘ç‡"], heatmap_data, label_opts=opts.LabelOpts(is_show=False))
        .set_global_opts(
            title_opts=opts.TitleOpts(title="è¯é¢‘çƒ­åŠ›å›¾"),
            visualmap_opts=opts.VisualMapOpts(),
        )
    )
    return heatmap


# Streamlitåº”ç”¨æ ‡é¢˜
st.title("æ–‡ç« URLè¯é¢‘åˆ†æ")

# ç”¨æˆ·è¾“å…¥URLçš„æ–‡æœ¬æ¡†
url = st.text_input('è¯·è¾“å…¥æ–‡ç« çš„URL:', '')

# æ„å»ºStreamlitä¾§è¾¹æ è¿›è¡Œå›¾å‹ç­›é€‰
chart_type = st.sidebar.selectbox(
    "é€‰æ‹©å›¾è¡¨ç±»å‹",
    ["è¯äº‘", "æŸ±çŠ¶å›¾", "æŠ˜çº¿å›¾", "é¥¼å›¾", "æ•£ç‚¹å›¾", "é›·è¾¾å›¾", "çƒ­åŠ›å›¾"]
)

# äº¤äº’è¿‡æ»¤ä½é¢‘è¯
min_occurrences = st.sidebar.slider('æœ€å°å‡ºç°æ¬¡æ•°:', 1, 100, 1)

if url:
    text_content = fetch_text_from_url(url)
    if text_content:
        cleaned_text = clean_text(text_content)
        words = word_segmentation(cleaned_text)
        word_freq = count_word_frequency(words)

        # ç¡®ä¿è¿”å›çš„æ˜¯Counterå¯¹è±¡
        filtered_words = Counter({word: freq for word, freq in word_freq.items() if freq >= min_occurrences})

        # æ ¹æ®ç”¨æˆ·é€‰æ‹©æ˜¾ç¤ºä¸åŒç±»å‹çš„å›¾è¡¨
        chart_functions = {
            "è¯äº‘": plot_wordcloud_with_pyecharts,
            "æŸ±çŠ¶å›¾": plot_bar_with_matplotlib,
            "æŠ˜çº¿å›¾":plot_line ,  # å¦‚æœéœ€è¦ï¼Œå¯ä»¥æ·»åŠ æŠ˜çº¿å›¾ç»˜åˆ¶é€»è¾‘
            "é¥¼å›¾": plot_pie_with_pyecharts,
            "æ•£ç‚¹å›¾": plot_scatter_with_pyecharts,
            "é›·è¾¾å›¾": plot_radar_with_pyecharts,
            "çƒ­åŠ›å›¾": plot_heatmap_with_pyecharts
        }

        if chart_type in chart_functions:
            chart_func = chart_functions[chart_type]
            chart = chart_func(filtered_words)
            if chart is not None:
                if isinstance(chart, str):  # å¦‚æœæ˜¯HTMLå­—ç¬¦ä¸²
                    st.components.v1.html(chart, height=650)
                else:
                    st.components.v1.html(chart.render_embed(), height=650)

        # å±•ç¤ºè¯é¢‘æ’åå‰20çš„è¯æ±‡
        top_20_words = word_freq.most_common(20)
        st.write("Top 20 Words:")
        st.table(top_20_words)